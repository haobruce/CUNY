---
title: "BHao_HW4"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
setwd("C:/Users/bhao/Google Drive/CUNY/git/DATA621/HW4")
```

##DATA EXPLORATION  

* Summary data indicate that 26.38% of records reported car crashes, which on average resulted in $5,702.18 in damages  
* Given that the dollar figures were imported as strings, we must first eliminate the dollar signs and commas and then convert to numbers in order to do much data exploration  
* Also, there are several variables that have NAs, i.e. AGE, YOJ, INCOME, HOME_VAL, CAR_AGE; we'll likely use caret's built-in preprocessing functions to address these NAs  
* We'll drop the INDEX variable here  

```{r}
insur = read.csv('insurance_training_data.csv', stringsAsFactors = TRUE)
str(insur)

# drop index column 
insur = subset(insur, select = -c(INDEX))

# eliminate dollar signs and commas and convert to numbers  
insur$INCOME = as.numeric(sub('\\$', '', sub('\\,', '', insur$INCOME)))
insur$HOME_VAL = as.numeric(sub('\\$', '', sub('\\,', '', insur$HOME_VAL)))
insur$BLUEBOOK = as.numeric(sub('\\$', '', sub('\\,', '', insur$BLUEBOOK)))
insur$OLDCLAIM = as.numeric(sub('\\$', '', sub('\\,', '', insur$OLDCLAIM)))

summary(insur)
# mean of actual accidents 
mean(insur[insur$TARGET_FLAG == 1, 'TARGET_AMT'])
```

##DATA PREPARATION  

* Since I'll be using the caret package for modeling, I need to convert the categorical variables to factors  
* We'll also use caret's medianImpute method within the preProcessing function to handle NAs  
* Well, the medianImpute preprocessing step isn't working as expected, so I'll manually impute the medians for NA data  
* Lastly, we'll use caret's center and scale preprocessing features to automatically transform the data during modeling  

```{r}
# convert categorical variables to factors 
insur$TARGET_FLAG = factor(insur$TARGET_FLAG, labels = c('no_crash', 'yes_crash'))
str(insur)

# median imputation
impute_median = function(x) replace(x, is.na(x), median(x, na.rm = TRUE))
insur$AGE = impute_median(insur$AGE)
insur$YOJ = impute_median(insur$YOJ)
insur$INCOME = impute_median(insur$INCOME)
insur$HOME_VAL = impute_median(insur$HOME_VAL)
insur$CAR_AGE = impute_median(insur$CAR_AGE)
```

##BUILD MODELS  

* We'll first build a linear regression model to estimate the cost of damage for those records with accidents  
* Then, we'll build a logistic regression model to predict the likelihood of an accident for all records  

##BUILD MODELS - LINEAR REGRESSION  

* For the linear regression, we'll just use those records where an accident occurred  
* In terms of setup, we are using 10-fold cross validation to measure out-of-sample performance and are using the same folds for each model to ensure comparable results    
* We then start by including all variables and then remove statistically insignificant ones at the 5% level until all remaining are significant  
* We then tried a glmnet model which combines lasso and ridge regression; given that it penalizes large magnitude and the number of non-zero coefficients, it can be used for variable selection  
* Lastly, we fit a random forest model just for fun  
* Based on the RMSE dot plot, the simple linear regression model based on only on BLUEBOOK performed the best and is our final model 
* You can also see the improvement as variables were removed; also note how well the glmnet rf model performed without manual tuning  

```{r message=FALSE, warning=FALSE}
library(caret)
library(caretEnsemble)

# drop TARGET_AMT variable 
insur_acc = insur[insur$TARGET_FLAG == 'yes_crash',]
insur_acc = subset(insur_acc, select = -c(TARGET_FLAG))

set.seed(123)
# use cross validation to compare out-of-sample ROC for all models  
# use the same folds for each model to ensure comparable results 
myFolds = createFolds(insur_acc$TARGET_AMT, k = 10)  

# used instead of method = 'cv', number = 10
myControl = trainControl(verboseIter = FALSE,savePredictions = TRUE, index = myFolds)  

# model using glm model
model_glm_full = train(TARGET_AMT ~ ., data = insur_acc, metric = 'RMSE', method = 'glm',
                  preProcess = c('center', 'scale'), trControl = myControl)
summary(model_glm_full)

# let's drop any statistically insignificant variables at 5% 
model_glm_sig1 = train(TARGET_AMT ~ SEX + BLUEBOOK + REVOKED + CAR_AGE, data = insur_acc,
                       metric = 'RMSE', method = 'glm', preProcess = c('center', 'scale'),
                       trControl = myControl)
summary(model_glm_sig1)

# let's again drop any additional statistically insigificant variables at 5% 
model_glm_sig2 = train(TARGET_AMT ~ BLUEBOOK, data = insur_acc,
                       metric = 'RMSE', method = 'glm', preProcess = c('center', 'scale'),
                       trControl = myControl)
summary(model_glm_sig2)

# let's try a glmnet model that combines ridge vs. lasso regression 
# since it penalizes either or both magnitude and number of non-zero coefficients, it can be used for variable selection
model_glmnet = train(TARGET_AMT ~ ., data = insur_acc, metric = 'RMSE', method = 'glmnet', 
                     preProcess = c('center', 'scale'), trControl = myControl)
coef(model_glmnet$finalModel, s = model_glmnet$finalModel$tuneValue$lambda)

# let's also model using random forest just for fun 
model_rf = train(TARGET_AMT ~ ., data = insur_acc, metric = 'RMSE', method = 'ranger', trControl = myControl)

# compare models 
model_list = list(glm_full = model_glm_full, glm_sig1 = model_glm_sig1, glm_sig2 = model_glm_sig2, 
                  glmnet = model_glmnet, rf = model_rf)

# collect resamples from the CV folds
resamps = resamples(model_list)
summary(resamps)
dotplot(resamps, metric = 'RMSE')
```

##BUILD MODELS - LOGISTIC REGRESSION  

* For the logistic regression model, we'll drop the TARGET_AMT 
* In terms of setup, we are using 10-fold cross validation to measure out-of-sample performance and are using the same folds for each model to ensure comparable results    
* We then start by including all variables and then remove statistically insignificant ones at the 5% level until all remaining are significant  
* We then tried a glmnet model which combines lasso and ridge regression; given that it penalizes large magnitude and the number of non-zero coefficients, it can be used for variable selection  
* Lastly, we fit a random forest model just for fun  
* Based on the ROC dot plot (the x-axis is actually AUC), the logistic regression model based on two backwardation steps performed the best and is our final selected model  
* You can also see the improvement as variables were removed; also note how well the glmnet rf model performed without manual tuning  

```{r message=FALSE, warning=FALSE}
# drop TARGET_AMT variable 
insur = subset(insur, select = -c(TARGET_AMT))

set.seed(123)
# use cross validation to compare out-of-sample ROC for all models  
# use the same folds for each model to ensure comparable results 
myFolds = createFolds(insur$TARGET_FLAG, k = 10)  

# confirm that folks preserve class distribution 
table(insur$TARGET_FLAG) / nrow(insur)
table(insur$TARGET_FLAG[myFolds$Fold1]) / length(myFolds$Fold1)

myControl = trainControl(summaryFunction = twoClassSummary, classProbs = TRUE, verboseIter = FALSE,
                         savePredictions = TRUE, index = myFolds)  # used instead of method = 'cv', number = 10

# model using glm model
model_glm_full = train(TARGET_FLAG ~ ., data = insur, metric = 'ROC', method = 'glm',
                  preProcess = c('center', 'scale'), trControl = myControl,
                  na.action = na.pass)
summary(model_glm_full)

# let's drop any statistically insignificant variables at 5% 
model_glm_sig1 = train(TARGET_FLAG ~ KIDSDRIV + INCOME + PARENT1 + HOME_VAL + MSTATUS + 
                       EDUCATION + JOB + TRAVTIME + CAR_USE + BLUEBOOK + TIF + CAR_TYPE +
                       OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + URBANICITY, data = insur,
                       metric = 'ROC', method = 'glm', preProcess = c('center', 'scale'),
                       trControl = myControl, na.action = na.pass)
summary(model_glm_sig1)

# let's again drop any additional statistically insigificant variables at 5% 
model_glm_sig2 = train(TARGET_FLAG ~ KIDSDRIV + INCOME + PARENT1 + HOME_VAL + MSTATUS + 
                       TRAVTIME + CAR_USE + BLUEBOOK + TIF + CAR_TYPE +
                       OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + URBANICITY, data = insur,
                       metric = 'ROC', method = 'glm', preProcess = c('center', 'scale'),
                       trControl = myControl, na.action = na.pass)
summary(model_glm_sig2)

# let's try a glmnet model that combines ridge vs. lasso regression 
# since it penalizes either or both magnitude and number of non-zero coefficients, it can be used for variable selection
model_glmnet = train(TARGET_FLAG ~ ., data = insur, metric = 'ROC', method = 'glmnet', 
                     preProcess = c('center', 'scale'), trControl = myControl,
                     na.action = na.pass)
coef(model_glmnet$finalModel, s = model_glmnet$finalModel$tuneValue$lambda)

# let's also model using random forest just for fun 
model_rf = train(TARGET_FLAG ~ ., data = insur, metric = 'ROC', method = 'ranger', 
                 preProcess = c('medianImpute'), trControl = myControl, na.action = na.pass)

# compare models 
model_list = list(glm_full = model_glm_full, glm_sig1 = model_glm_sig1, glm_sig2 = model_glm_sig2, 
                  glmnet = model_glmnet, rf = model_rf)

# collect resamples from the CV folds
resamps = resamples(model_list)
summary(resamps)
dotplot(resamps, metric = 'ROC')
```

##SELECT MODEL  

* The final models were selected because they performed the best, are very simple and are highly intuitive  
* For the linear regression model, it makes sense that the BLUEBOOK variable was the main (and only) factor as the cost of damage in an accident is related to the value of the car (excluding injuries, other property, etc.)  
* For the logistic regression model, higher values for the following variables were associated with higher probability of an accident: KIDSDRIV, PARENT1, MSTATUS, TRAVTIME, Sports Car & SUV, CLM_FREQ, REVOKED, MVR_PTS  
* Lower values for the following variables were associated with higher probability of accident: INCOME, HOME_VAL, BLUEBOOK, OLDCLAIM, Highly Urban  
* After the final models were selected, we then re-fit the models to the entire data set (i.e. no cross validation) to ensure that we maximize use of all the available data   
* The final logistic regression model is then used to predict the classes and probabilities  
* Finally, the final linear regression model is used to predict the cost of damage for only those predicted accidents  

```{r}
final_linReg = train(TARGET_AMT ~ BLUEBOOK, data = insur_acc,
                     metric = 'RMSE', method = 'glm', preProcess = c('center', 'scale'),
                     trControl = trainControl(verboseIter = FALSE))
summary(final_linReg)

final_logReg = train(TARGET_FLAG ~ KIDSDRIV + INCOME + PARENT1 + HOME_VAL + MSTATUS + 
                     TRAVTIME + CAR_USE + BLUEBOOK + TIF + CAR_TYPE +
                     OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + URBANICITY, data = insur,
                     metric = 'ROC', method = 'glm', preProcess = c('center', 'scale'),
                     trControl = trainControl(summaryFunction = twoClassSummary, classProbs = TRUE, verboseIter = FALSE),
                     na.action = na.exclude)
summary(final_logReg)

# import and cleanse test data 
insur_test = read.csv('insurance-evaluation-data.csv', stringsAsFactors = TRUE)
# eliminate dollar signs and commas and convert to numbers  
insur_test$INCOME = as.numeric(sub('\\$', '', sub('\\,', '', insur_test$INCOME)))
insur_test$HOME_VAL = as.numeric(sub('\\$', '', sub('\\,', '', insur_test$HOME_VAL)))
insur_test$BLUEBOOK = as.numeric(sub('\\$', '', sub('\\,', '', insur_test$BLUEBOOK)))
insur_test$OLDCLAIM = as.numeric(sub('\\$', '', sub('\\,', '', insur_test$OLDCLAIM)))
insur_test$AGE = impute_median(insur_test$AGE)
insur_test$YOJ = impute_median(insur_test$YOJ)
insur_test$INCOME = impute_median(insur_test$INCOME)
insur_test$HOME_VAL = impute_median(insur_test$HOME_VAL)
insur_test$CAR_AGE = impute_median(insur_test$CAR_AGE)

# predict classes and probabilities
pred_class = predict(final_logReg, newdata = insur_test)
pred_prob = predict(final_logReg, newdata = insur_test, type = 'prob')
insur_test$TARGET_FLAG = pred_class

# predict cost of damage 
insur_test_acc = insur_test[insur_test$TARGET_FLAG == 'yes_crash',]
pred_cost = predict(final_linReg, newdata = insur_test_acc)
insur_test[insur_test$TARGET_FLAG == 'yes_crash', 'TARGET_AMT'] = pred_cost
insur_test[insur_test$TARGET_FLAG == 'no_crash', 'TARGET_AMT'] = 0

# finalize predictions
insur_test_classified = cbind(pred_prob, insur_test)
write.csv(insur_test_classified, 'insurance-evaluation-prediction.csv')

# the predictions for the evaluation data show less likelihood of accident compared to the training set  
table(pred_class) / length(pred_class)

# the predicted damage is relatively close to the average damge cost of the training set 
mean(insur_test[insur_test$TARGET_FLAG == 'yes_crash', 'TARGET_AMT'])
```


