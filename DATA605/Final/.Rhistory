mutate(ts_interaction_first = ts_interaction_first %>% as.POSIXct("%Y-%m-%d %H:%M:%S"),
ts_reply_at_first = ts_reply_at_first %>% plyr::mapvalues('', NA) %>%
as.POSIXct("%Y-%m-%d %H:%M:%S"),
ts_accepted_at_first = ts_accepted_at_first %>% plyr::mapvalues('', NA) %>%
as.POSIXct("%Y-%m-%d %H:%M:%S"),
ts_booking_at = ts_booking_at %>% plyr::mapvalues('', NA) %>%
as.POSIXct("%Y-%m-%d %H:%M:%S"),
m_reply_time = as.numeric(ts_reply_at_first - ts_interaction_first),
ds_checkin_first = ds_checkin_first %>% plyr::mapvalues('', NA) %>% as.Date(),
ds_checkout_first = ds_checkout_first %>% plyr::mapvalues('', NA) %>% as.Date(),
m_stay_length = as.numeric(ds_checkout_first - ds_checkin_first),
m_lead_time = as.numeric(ds_checkin_first - ts_interaction_first),
target_booking = factor(if_else(is.na(ts_booking_at), 0, 1),
labels = c('not_booked', 'booked')),
target_accept = factor(if_else(is.na(ts_accepted_at_first), 0, 1),
labels = c('not_accepted', 'accepted')),
target_reply = factor(if_else(is.na(ts_reply_at_first), 0, 1),
labels = c('not_replied', 'replied'))
)
listings = read.csv(paste0(path, 'listings.csv'), stringsAsFactors = FALSE)
users = read.csv(paste0(path, 'users.csv'), stringsAsFactors = FALSE)
# combine data sets
# there are 11 user_ids in contacts that are not in users; however, this is not material or worrisome
combined_data = contacts %>% left_join(listings) %>%
left_join(users, by = c('id_guest_anon' = 'id_user_anon')) %>%
mutate(m_guests_capacity = m_guests - dim_person_capacity)
user_funnel = contacts %>% filter(dim_contact_channel_first != 'instant_booked') %>%
group_by(id_guest_anon) %>%
summarise(n_lst = sum(if_else(!is.na(id_listing_anon), 1, 0)),
n_int = sum(if_else(!is.na(ts_interaction_first), 1, 0)),
n_rep = sum(if_else(!is.na(ts_reply_at_first), 1, 0)),
n_acc = sum(if_else(!is.na(ts_accepted_at_first), 1, 0)),
n_bkd = sum(if_else(!is.na(ts_booking_at), 1, 0))
) %>%
arrange(desc(n_lst))
user_funnel %>% group_by(n_bkd) %>% summarise(m_lst = mean(n_lst))
user_funnel = combined_data %>% filter(dim_contact_channel_first != 'instant_booked') %>%
group_by(id_guest_anon) %>%
summarise(n_lst = sum(if_else(!is.na(id_listing_anon), 1, 0)),
n_int = sum(if_else(!is.na(ts_interaction_first), 1, 0)),
n_rep = sum(if_else(!is.na(ts_reply_at_first), 1, 0)),
n_acc = sum(if_else(!is.na(ts_accepted_at_first), 1, 0)),
n_bkd = sum(if_else(!is.na(ts_booking_at), 1, 0))
) %>%
arrange(desc(n_lst))
combined_data %>% group_by(if_else(!is.na(ts_booking_at), 1, 0))
combined_data %>% group_by(mutate(bkd = if_else(!is.na(ts_booking_at), 1, 0)))
combined_data %>% mutate(bkd = if_else(!is.na(ts_booking_at), 1, 0)) %>% group_by(bkd)
combined_data %>% mutate(bkd = if_else(!is.na(ts_booking_at), 1, 0)) %>% group_by(bkd)
combined_data %>% mutate(bkd = if_else(!is.na(ts_booking_at), 1, 0)) %>% group_by(bkd) %>%
summarise(mean_reviews = mean(dim_total_reviews))
setwd("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final")
kaggle = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/train.csv")
str(kaggle)
# set X = LotArea and Y = SalePrice
X = kaggle$LotArea
Y = kaggle$SalePrice
# set X = LotArea and Y = SalePrice
X = kaggle$LotArea
Y = kaggle$SalePrice
summary(X)
summary(Y)
library(dplyr)
df = kaggle %>% select(SalePrice, LotArea)
# set X = LotArea and Y = SalePrice
df = kaggle %>% select(SalePrice, LotArea)
X = df$LotArea
Y = df$SalePrice
summary(df)
quantile(df$LotArea, 4)
quantile(df$LotArea, 0.75)
# set X = LotArea and Y = SalePrice
df = kaggle %>% select(SalePrice, LotArea)
summary(df)
quantile(df$LotArea, 0.75)
x = quantile(df$LotArea, 0.75)
y = quantile(df$SalePrice, 0.25)
df %>% filter(SalePrice > y) %>% mutate(n = n())
str(df)
df %>% filter(SalePrice > y) %>% summarise(n = n())
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n())
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
nrow(df)
df %>% filter(LotArea < x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr'))
df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr')) %>%
select(topQtrX, botQtrY)
table(df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr')) %>%
select(topQtrX, botQtrY))
tbl = table(df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr')) %>%
select(topQtrX, botQtrY))
library(MASS)
chisq.test(tbl)
tbl
chisq.test(tbl)
library(ggplot2)
summary(df)
library(gridExtra)
p1 = df %>% ggplot(aes(y = LotArea)) + geom_boxplot()
p1
p1 = df %>% ggplot(aes(x = LotArea)) + geom_boxplot()
p1
p1 = df %>% select(LotArea) %>% ggplot(aes(x = LotArea)) + geom_boxplot()
df %>% select(LotArea) %>% ggplot(aes(x = LotArea)) + geom_boxplot()
df %>% select(LotArea)
summary(df)
df %>% select(LotArea)
df %>% select(SalePrice)
df
library(dplyr)
df %>% select(SalePrice)
df %>% ggplot(aes(x = LotArea)) + geom_boxplot()
df %>% ggplot(aes(x = LotArea, y = LotArea)) + geom_boxplot()
df %>% ggplot(aes(x = factor(0), y = LotArea)) + geom_boxplot()
p1 = df %>% ggplot(aes(x = factor(0), y = SalePrice)) + geom_boxplot()
p2 = df %>% ggplot(aes(x = factor(0), y = LotArea)) + geom_boxplot()
grid.arrange(p1, p2, ncol = 2)
df %>% ggplot(x = LotArea, y = SalePrice) %>% geom_point()
df %>% ggplot(aes(x = LotArea, y = SalePrice)) %>% geom_point()
df %>% ggplot(aes(x = LotArea, y = SalePrice)) + geom_point()
bc = boxcox(lm(SalePrice ~ LotArea, df))
bc = boxcox(lm(SalePrice ~ LotArea, data = df))
lm(SalePrice ~ LotArea, data = df)
boxcox(lm(SalePrice ~ LotArea, data = df))
bc = boxcox(SalePrice ~ LotArea, data = df)
head(bc$x)
head(df$LotArea)
cor(bc$x, bc$y)
cor(df$LotArea, df$SalePrice)
cor(bc$x, bc$y, method = 'spearman')
cor(bc$x, bc$y, method)
cor(bc$x, bc$y)
cor(df$LotArea, df$SalePrice)
cor(df)
cor_mat = cor(df)
prec_mat = solve(cor_mat)
solve(cor_mat)
cor_mat %*% prec_mat
prec_mat %*% cor_mat
fitdistr(df$LotArea)
hist(df$LotArea)
fitdistr(df$LotArea, densfun = 'lognormal')
fit = fitdistr(df$LotArea, densfun = 'lognormal')
fit$estimate
fit$estimate$meanLog
fit$estimate[1]
fit$estimate
# fit lognormal distribution to data
fit = fitdistr(df$LotArea, densfun = 'lognormal')
meanLog = fit$estimate[1]
sdLog = fit$estimate[2]
samp = rlnorm(1000, meanLog, sdLog)
p1 = df$LotArea %>% ggplot(aes(x = LotArea)) + geom_histogram()
p1 = df %>% ggplot(aes(x = LotArea)) + geom_histogram()
p1
p2 = ggplot(aes(x = samp)) + geom_histogram()
samp
typeof(samp)
p2 = qplot(samp, geom = 'histogram')
p2
p1 = qplot(df$LotArea, geom = 'histogram')
grid.arrange(p1, p2, ncol = 1)
grid.arrange(p1, p2, ncol = 2)
p1 = df %>% ggplot(aes(x = LotArea)) + geom_histogram()
p1 = df %>% ggplot(aes(x = LotArea)) + geom_histogram() + xlim(c(0, 40000))
p1
# fit lognormal distribution to data
fit = fitdistr(df$LotArea, densfun = 'lognormal')
meanLog = fit$estimate[1]
sdLog = fit$estimate[2]
samp = rlnorm(1000, meanLog, sdLog)
typeof(samp)
p1 = df %>% ggplot(aes(x = LotArea)) + geom_histogram() + xlim(c(0, 40000))
p2 = qplot(samp, geom = 'histogram')
grid.arrange(p1, p2, ncol = 2)
# fit lognormal distribution to data
fit = fitdistr(df$LotArea, densfun = 'lognormal')
meanLog = fit$estimate[1]
sdLog = fit$estimate[2]
samp = rlnorm(1000, meanLog, sdLog)
typeof(samp)
p1 = df %>% ggplot(aes(x = LotArea)) + geom_histogram() + xlim(c(0, 50000))
p2 = qplot(samp, geom = 'histogram')
grid.arrange(p1, p2, ncol = 2)
library(caret)
library(caret)
set.seed(123)
myControl = trainControl(method = 'cv', number = 5, verboseIter = TRUE)
#try glmnet model
glmnet_model = train(SalePrice ~ ., data = kaggle, method = 'glmnet', trControl = myControl)
glmnet_model = train(SalePrice ~ ., data = kaggle, method = 'glmnet', trControl = myControl,
preProcess = c('medianImpute', 'center', 'scale'))
summary(kaggle)
glmnet_model = train(SalePrice ~ ., data = kaggle, method = 'glmnet', trControl = myControl,
preProcess = c('medianImpute', 'center', 'scale'))
str(kaggle)
X = kaggle[,-ncol(kaggle)]
str(X)
Y = kaggle$SalePrice
train(X, Y)
train(X, Y, method = 'glmnet')
train(X, Y, method = 'glmnet', preProcess = 'medianImpute')
train(X, Y, method = 'lm', preProcess = 'medianImpute')
train(X, Y, preProcess = 'medianImpute')
summary(X)
install.packages("imputeMissings")
library(imputeMissings)
X = impute(X, method = 'median/model')
X = kaggle[,-ncol(kaggle)]
X = impute(X, method = 'median/model')
X = impute(X, method = 'median/mode')
summary(X)
glmnet_model = train(Y ~ X, method = 'glmnet', trControl = myControl,
preProcess = c('medianImpute', 'center', 'scale'))
glmnet_model = train(X, Y, method = 'glmnet', trControl = myControl,
preProcess = c('center', 'scale'))
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
summary(clean)
glmnet_model = train(SalePrice ~ ., data = clean, method = 'glmnet', trControl = myControl,
preProcess = c('center', 'scale'))
summary(glmnet_model)
(glmnet_model$bestTune)
glmnet_model$results
rf_model = train(SalePrice ~ ., data = clean, method = 'ranger', trControl = myControl,
preProcess = c('center', 'scale'))
model_list = list(glmnet = glmnet_model, rf = rf_model)
resamps = resamples(model_list)
summary(resamps)
dotplot(resamps, metric = 'RMSE')
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test
summary(test)
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_clean = impute(test)
summary(test)
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
library(imputeMissings)
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
clean = impute(kaggle, method = 'median')  # impute medians for missing data
setwd("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final")
library(dplyr)
library(ggplot2)
library(gridExtra)
kaggle = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/train.csv")
#str(kaggle)
library(caret)
library(caret)
library(imputeMissings)
set.seed(123)
myControl = trainControl(method = 'cv', number = 5, verboseIter = TRUE)
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
rf_model = train(SalePrice ~ ., data = clean, method = 'ranger', trControl = myControl,
preProcess = c('center', 'scale'))
test_pred = predict(rf_model$finalModel, data = test_clean)
summary(test_clean)
test_pred = predict(rf_model$finalModel, newdata = test_clean)
rf_model$finalModel
test_pred = predict(rf_model$finalModel, data = test_clean)
final_model = rf_model$finalModel
test_pred = predict(finalModel, newdata = test_clean)
test_pred = predict(final_model, newdata = test_clean)
glmnet_model = train(SalePrice ~ ., data = clean, method = 'glmnet', trControl = myControl,
preProcess = c('center', 'scale'))
?ranger
final_model = train(SalePrice ~ ., data = clean, method = 'ranger',
rf_model$modelInfo
#load test data
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
rf_model$modelInfo
final_model = train(SalePrice ~ ., data = clean, method = 'ranger',
rf_model$finalModel
#load test data
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
rf_model$finalModel
rfm = rf_model$finalModel
summary(rfm)
rfm
final_model = train(SalePrice ~ ., data = clean, method = 'ranger', mtry = rfm$mtry)
final_model = train(SalePrice ~ ., data = clean, method = 'ranger', param$mtry = rfm$mtry)
rfm$mtry
final_model = train(SalePrice ~ ., data = clean, method = 'ranger', param$mtry = rfm$mtry)
final_model = train(SalePrice ~ ., data = clean, method = 'ranger', param$mtry = rfm$mtry)
final_model = train(SalePrice ~ ., data = clean, method = 'ranger', mtry = rfm$mtry)
final_model = ranger(SalePrice ~ ., data = clean, mtry = rfm$mtry)
rfm = rf_model$finalModel
rfm
ncol(clean)
rf_model = train(SalePrice ~ ., data = clean, method = 'ranger', trControl = myControl,
preProcess = c('center', 'scale'))
test_pred = predict(rf_model, newdata = test_clean)
test_pred
write.csv(test_pred, "C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/rf_pred.csv")
test_pred = cbind(test, test_pred)
test_pred
str(test_pred)
test_pred = cbind(test, test_pred) %>% mutate(SalesPrice = tes_pred) %>% select(Id, SalesPrice)
test_pred = cbind(test, test_pred) %>% mutate(SalesPrice = test_pred) %>% select(Id, SalesPrice)
test_pred = predict(rf_model, newdata = test_clean)
test_pred = cbind(test, test_pred) %>% mutate(SalesPrice = test_pred) %>% select(Id, SalesPrice)
write.csv(test_pred, "C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/rf_pred.csv")
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_pred = predict(rf_model, newdata = test_clean)
test_pred = cbind(test, test_pred) %>% mutate(SalePrice = test_pred) %>% select(Id, SalePrice)
write.csv(test_pred, "C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/rf_pred.csv")
setwd("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final")
library(dplyr)
library(ggplot2)
library(gridExtra)
kaggle = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/train.csv")
#str(kaggle)
library(MASS)
df = kaggle %>% select(SalePrice, LotArea)
str(kaggle)
df = kaggle %>% select(SalePrice, LotArea)
kaggle %>% select(SalePrice, LotArea)
library(MASS)
X = df$LotArea
library(dplyr)
df = kaggle %>% select(SalePrice, LotArea)
library(dplyr)
df = kaggle %>% dplyr::select(SalePrice, LotArea)
library(MASS)
df = kaggle %>% dplyr::select(SalePrice, LotArea)
X = df$LotArea
Y = df$SalePrice
# set x = min of 4th quartile and y = min of 2nd quartile
x = quantile(df$LotArea, 0.75)
y = quantile(df$SalePrice, 0.25)
#a. P(X>x | Y>y) = 31.23% probability that lot area is greater than 0.75 quantile when
#sale price is greater than 0.25 quantile
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
#b. P(X>x, Y>y) = 23.42% probability that lot area is greater than 0.75 quantile AND
#sale price is greater than 0.25 quantile
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
nrow(df)
#c. P(X<x | Y>y) = 68.77% probability that lot area is less than 0.75 quantile when
#sale price is greater than 0.25 quantile
df %>% filter(LotArea < x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
#chi-square test
tbl = table(df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr')) %>%
select(topQtrX, botQtrY))
library(MASS)
df = kaggle %>% dplyr::select(SalePrice, LotArea)
X = df$LotArea
Y = df$SalePrice
# set x = min of 4th quartile and y = min of 2nd quartile
x = quantile(df$LotArea, 0.75)
y = quantile(df$SalePrice, 0.25)
#a. P(X>x | Y>y) = 31.23% probability that lot area is greater than 0.75 quantile when
#sale price is greater than 0.25 quantile
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
#b. P(X>x, Y>y) = 23.42% probability that lot area is greater than 0.75 quantile AND
#sale price is greater than 0.25 quantile
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
nrow(df)
#c. P(X<x | Y>y) = 68.77% probability that lot area is less than 0.75 quantile when
#sale price is greater than 0.25 quantile
df %>% filter(LotArea < x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
#chi-square test
tbl = table(df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr')) %>%
dplyr::select(topQtrX, botQtrY))
chisq.test(tbl)
summary(df)
p1 = df %>% ggplot(aes(x = factor(0), y = SalePrice)) + geom_boxplot()
p2 = df %>% ggplot(aes(x = factor(0), y = LotArea)) + geom_boxplot()
grid.arrange(p1, p2, ncol = 2)
df %>% ggplot(aes(x = LotArea, y = SalePrice)) + geom_point()
#box-cox transformation
bc = boxcox(SalePrice ~ LotArea, data = df)
cor(bc$x, bc$y, method = 'spearman')
cor(df$LotArea, df$SalePrice)
cor_mat = cor(df)
prec_mat = solve(cor_mat)  # invert correlation matrix
cor_mat %*% prec_mat  # results in identity matrix
prec_mat %*% cor_mat  # results in identity matrix
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
library(imputeMissings)
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_pred = predict(rf_model, newdata = test_clean)
library(caret)
library(imputeMissings)
set.seed(123)
myControl = trainControl(method = 'cv', number = 5, verboseIter = TRUE)
#try glmnet model
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
glmnet_model = train(SalePrice ~ ., data = clean, method = 'glmnet', trControl = myControl,
preProcess = c('center', 'scale'))
#try random forest model
rf_model = train(SalePrice ~ ., data = clean, method = 'ranger', trControl = myControl,
preProcess = c('center', 'scale'))
#compare models
model_list = list(glmnet = glmnet_model, rf = rf_model)
#collect resamples from the CV folds
resamps = resamples(model_list)
dotplot(resamps, metric = 'RMSE')
#load test data
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
setwd("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final")
library(dplyr)
library(ggplot2)
library(gridExtra)
kaggle = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/train.csv")
#str(kaggle)
library(MASS)
df = kaggle %>% dplyr::select(SalePrice, LotArea)
X = df$LotArea
Y = df$SalePrice
# set x = min of 4th quartile and y = min of 2nd quartile
x = quantile(df$LotArea, 0.75)
y = quantile(df$SalePrice, 0.25)
#a. P(X>x | Y>y) = 31.23% probability that lot area is greater than 0.75 quantile when
#sale price is greater than 0.25 quantile
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
#b. P(X>x, Y>y) = 23.42% probability that lot area is greater than 0.75 quantile AND
#sale price is greater than 0.25 quantile
df %>% filter(LotArea > x & SalePrice > y) %>% summarise(n = n()) /
nrow(df)
#c. P(X<x | Y>y) = 68.77% probability that lot area is less than 0.75 quantile when
#sale price is greater than 0.25 quantile
df %>% filter(LotArea < x & SalePrice > y) %>% summarise(n = n()) /
df %>% filter(SalePrice > y) %>% summarise(n = n())
#chi-square test
tbl = table(df %>% mutate(topQtrX = if_else(LotArea > x, 'TopQtr', 'Bottom3Qtr'),
botQtrY = if_else(SalePrice > y, 'Top3Qtr', 'BottomQtr')) %>%
dplyr::select(topQtrX, botQtrY))
chisq.test(tbl)
summary(df)
p1 = df %>% ggplot(aes(x = factor(0), y = SalePrice)) + geom_boxplot()
p2 = df %>% ggplot(aes(x = factor(0), y = LotArea)) + geom_boxplot()
grid.arrange(p1, p2, ncol = 2)
df %>% ggplot(aes(x = LotArea, y = SalePrice)) + geom_point()
#box-cox transformation
bc = boxcox(SalePrice ~ LotArea, data = df)
cor(bc$x, bc$y, method = 'spearman')
cor(df$LotArea, df$SalePrice)
cor_mat = cor(df)
prec_mat = solve(cor_mat)  # invert correlation matrix
cor_mat %*% prec_mat  # results in identity matrix
prec_mat %*% cor_mat  # results in identity matrix
# fit lognormal distribution to data
fit = fitdistr(df$LotArea, densfun = 'lognormal')
meanLog = fit$estimate[1]
sdLog = fit$estimate[2]
samp = rlnorm(1000, meanLog, sdLog)
typeof(samp)
p1 = df %>% ggplot(aes(x = LotArea)) + geom_histogram() + xlim(c(0, 50000))
p2 = qplot(samp, geom = 'histogram')
grid.arrange(p1, p2, ncol = 2)
library(caret)
library(imputeMissings)
library(caret)
library(imputeMissings)
set.seed(123)
myControl = trainControl(method = 'cv', number = 5, verboseIter = TRUE)
#try glmnet model
clean = impute(kaggle, method = 'median/mode')  # impute medians for missing data
glmnet_model = train(SalePrice ~ ., data = clean, method = 'glmnet', trControl = myControl,
preProcess = c('center', 'scale'))
#try random forest model
rf_model = train(SalePrice ~ ., data = clean, method = 'ranger', trControl = myControl,
preProcess = c('center', 'scale'))
#compare models
model_list = list(glmnet = glmnet_model, rf = rf_model)
#collect resamples from the CV folds
resamps = resamples(model_list)
dotplot(resamps, metric = 'RMSE')
#load test data
test = read.csv("C:/Users/bhao/Google Drive/CUNY/git/DATA605/Final/test.csv")
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_clean = impute(test, method = 'median/mode')  # impute medians for missing data
test_clean = imputeMissing::impute(test, method = 'median/mode')  # impute medians for missing data
test_clean = imputeMissings::impute(test, method = 'median/mode')  # impute medians for missing data
library(caret)
set.seed(123)
myControl = trainControl(method = 'cv', number = 5, verboseIter = TRUE)
#try glmnet model
clean = imputeMissings::impute(kaggle, method = 'median/mode')  # impute medians for missing data
glmnet_model = train(SalePrice ~ ., data = clean, method = 'glmnet', trControl = myControl,
preProcess = c('center', 'scale'))
#try random forest model
rf_model = train(SalePrice ~ ., data = clean, method = 'ranger', trControl = myControl,
preProcess = c('center', 'scale'))
#compare models
model_list = list(glmnet = glmnet_model, rf = rf_model)
#collect resamples from the CV folds
resamps = resamples(model_list)
dotplot(resamps, metric = 'RMSE')
